{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with the same Spaceship Titanic data, like the previous Lab. The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab, you should try different ensemble methods in order to see if can obtain a better model than before. In order to do a fair comparison, you should perform the same feature scaling, engineering applied in previous Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Cargar los datos\n",
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "\n",
    "# Convertir las variables categóricas a numéricas usando One-Hot Encoding\n",
    "spaceship_encoded = pd.get_dummies(spaceship)\n",
    "\n",
    "# Separar las características (X) y la variable objetivo (y)\n",
    "X = spaceship_encoded.drop('Transported', axis=1)\n",
    "y = spaceship_encoded['Transported']\n",
    "\n",
    "# 1. Imputar valores faltantes (NaN) usando la media de cada columna\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# 2. Escalado de características\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# 3. Selección de características (usamos SelectKBest para seleccionar las mejores características)\n",
    "selector = SelectKBest(f_classif, k=10)  # Seleccionamos las 10 mejores características\n",
    "X_selected = selector.fit_transform(X_scaled, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.77428657e-02 -3.40589867e-01  3.06649292e-01 -2.69022628e-01\n",
      "   9.42847454e-01 -5.69867136e-01  7.73480278e-01 -7.32770025e-01\n",
      "  -5.11013194e-01  6.85312647e-01]\n",
      " [-8.24922656e-01 -3.40589867e-01 -2.76663422e-01 -2.69022628e-01\n",
      "   9.42847454e-01 -5.69867136e-01  7.73480278e-01 -7.32770025e-01\n",
      "  -5.11013194e-01  6.85312647e-01]\n",
      " [-5.77428657e-02 -3.40589867e-01 -2.76663422e-01 -2.69022628e-01\n",
      "  -1.06061696e+00  1.75479500e+00 -1.29285779e+00  1.36468464e+00\n",
      "   1.95689664e+00 -1.45918801e+00]\n",
      " [-6.15691804e-01  4.30826867e-17  5.91192079e-01 -2.69022628e-01\n",
      "  -1.06061696e+00 -5.69867136e-01  7.73480278e-01 -7.32770025e-01\n",
      "  -5.11013194e-01  6.85312647e-01]\n",
      " [ 5.00206073e-01 -3.40589867e-01 -2.76663422e-01 -2.69022628e-01\n",
      "  -1.06061696e+00  1.75479500e+00 -1.29285779e+00  1.36468464e+00\n",
      "   1.95689664e+00 -1.45918801e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dividir el conjunto de datos en conjunto de entrenamiento y conjunto de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Mostrar las primeras filas de X_train escaladas\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection** - now you will try to apply different ensemble methods in order to get a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de Bagging: 0.7550\n",
      "Precisión de Pasting: 0.7062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Crear el clasificador base (Decision Tree)\n",
    "base_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Bagging Classifier\n",
    "bagging_model = BaggingClassifier(base_model, n_estimators=100, random_state=42)\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación de Bagging\n",
    "y_pred_bagging = bagging_model.predict(X_test)\n",
    "bagging_accuracy = accuracy_score(y_test, y_pred_bagging)\n",
    "print(f\"Precisión de Bagging: {bagging_accuracy:.4f}\")\n",
    "\n",
    "# Pasting Classifier (usando VotingClassifier como ejemplo de un ensamblado)\n",
    "pasting_model = VotingClassifier(estimators=[('tree', base_model)], voting='hard')\n",
    "pasting_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación de Pasting\n",
    "y_pred_pasting = pasting_model.predict(X_test)\n",
    "pasting_accuracy = accuracy_score(y_test, y_pred_pasting)\n",
    "print(f\"Precisión de Pasting: {pasting_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de Random Forest: 0.7487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Crear el modelo Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenamiento y evaluación\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y evaluación de la precisión\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Precisión de Random Forest: {rf_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de Gradient Boosting: 0.7757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Crear el modelo Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenamiento y evaluación\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y evaluación de la precisión\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"Precisión de Gradient Boosting: {gb_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de AdaBoost: 0.7476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Crear el modelo AdaBoost\n",
    "ada_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenamiento y evaluación\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y evaluación de la precisión\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "ada_accuracy = accuracy_score(y_test, y_pred_ada)\n",
    "print(f\"Precisión de AdaBoost: {ada_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is the best and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparación de precisiones:\n",
      "Bagging Precision: 0.7550\n",
      "Pasting Precision: 0.7062\n",
      "Random Forest Precision: 0.7487\n",
      "Gradient Boosting Precision: 0.7757\n",
      "AdaBoost Precision: 0.7476\n"
     ]
    }
   ],
   "source": [
    "# Comparar las precisiones de los modelos\n",
    "print(\"\\nComparación de precisiones:\")\n",
    "print(f\"Bagging Precision: {bagging_accuracy:.4f}\")\n",
    "print(f\"Pasting Precision: {pasting_accuracy:.4f}\")\n",
    "print(f\"Random Forest Precision: {rf_accuracy:.4f}\")\n",
    "print(f\"Gradient Boosting Precision: {gb_accuracy:.4f}\")\n",
    "print(f\"AdaBoost Precision: {ada_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#comment here\n",
    "En términos de precisión del modelo para la métrica MAE, el modelo con el valor más bajo (en este caso, Gradient Boosting) es preferible. Sin embargo, la elección final debe equilibrar precisión, tiempo de entrenamiento, interpretabilidad y estabilidad del rendimiento del modelo según los objetivos del proyecto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
